{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed8a2a-81c2-4f3f-8103-b7173b48e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0  ──────────────────────────────────────────────────────────────\n",
    "import numpy as np\n",
    "import torch\n",
    "import dgl\n",
    "\n",
    "# 👇 import the encoder implementation that came with SpaFormer\n",
    "#    (the file you uploaded as edcoder.py)\n",
    "import importlib.util, pathlib, sys\n",
    "spec = importlib.util.spec_from_file_location(\"edcoder\", pathlib.Path(\"Data\") / \"edcoder.py\")\n",
    "edcoder = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"edcoder\"] = edcoder\n",
    "spec.loader.exec_module(edcoder)\n",
    "\n",
    "# --- convenience wrapper --------------------------------------------------\n",
    "def build_graph(edge_index, num_nodes):\n",
    "    \"\"\"\n",
    "    edge_index: np.ndarray with shape (2, E) – COO (src, dst)\n",
    "    returns    : DGLGraph on CPU\n",
    "    \"\"\"\n",
    "    g = dgl.graph((edge_index[0], edge_index[1]), num_nodes=num_nodes)\n",
    "    g = dgl.add_self_loop(g)          # SpaFormer expects self-loops\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e5e74-de97-483b-b30f-c1cdb5dac46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1  ──────────────────────────────────────────────────────────────\n",
    "# paths\n",
    "PP_DIR = pathlib.Path(\"Data/spaformer_prepared\")\n",
    "\n",
    "# ① expression matrix  (cells × genes)        float32\n",
    "X_np     = np.load(PP_DIR / \"X.npy\")          # (N, G)\n",
    "# ② spatial coordinates (cells × 2, 0-1 norm) float32\n",
    "C_np     = np.load(PP_DIR / \"C.npy\")          # (N, 2)\n",
    "# ③ graph (2 × E) int32  – already K-NN, undirected, COO\n",
    "edges_np = np.load(PP_DIR / \"edges.npy\")      # (2, E)\n",
    "\n",
    "N, G = X_np.shape\n",
    "print(f\"cells: {N}   genes: {G}   edges: {edges_np.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf88dc-db2b-46c6-8a30-652841b8704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2  ──────────────────────────────────────────────────────────────\n",
    "# torch tensors on CPU\n",
    "X_t = torch.from_numpy(X_np)        # (N, G)\n",
    "C_t = torch.from_numpy(C_np)        # (N, 2)\n",
    "\n",
    "# DGL graph\n",
    "g = build_graph(edges_np, N)\n",
    "\n",
    "print(g)          # sanity check\n",
    "print(\"X_t\", X_t.shape, X_t.dtype)\n",
    "print(\"C_t\", C_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec464c07-e10e-4d65-b059-11137efe7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3  ──────────────────────────────────────────────────────────────\n",
    "# ⚙️  hyper-params ------  (tweak as you like)\n",
    "EMBED_DIM    = 256   # latent dimension per token (cell)\n",
    "DEPTH        = 6     # number of transformer layers\n",
    "NUM_HEADS    = 8\n",
    "\n",
    "# 🏗  build encoder-only model\n",
    "model = edcoder.EDcoder(\n",
    "            gene_dim     = G,        # input feature size\n",
    "            pos_dim      = 2,        # (x,y)\n",
    "            embed_dim    = EMBED_DIM,\n",
    "            depth        = DEPTH,\n",
    "            num_heads    = NUM_HEADS,\n",
    "            decoder      = False,    # 👈 turn off the decoder\n",
    "        )\n",
    "\n",
    "print(f\"Encoder params: {sum(p.numel() for p in model.parameters())/1e6:.2f} M\")\n",
    "model.eval()          # inference mode (no dropout, no grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c879dc-9f6a-420a-b6ea-423f0f16c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4  ──────────────────────────────────────────────────────────────\n",
    "with torch.no_grad():                         # inference\n",
    "    # 👇 forward signature may differ; many repos use (g, X, pos)\n",
    "    #    or concatenate C into X inside. Adjust if needed.\n",
    "    latent_t = model(g, X_t, C_t)             # (N, EMBED_DIM)\n",
    "\n",
    "print(\"latent_t:\", latent_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83cbb3b-e612-4a12-b311-637e8a738d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5  ──────────────────────────────────────────────────────────────\n",
    "LATENT_PATH = PP_DIR / \"latent.npy\"\n",
    "np.save(LATENT_PATH, latent_t.cpu().numpy())\n",
    "print(\"Saved →\", LATENT_PATH)\n",
    "\n",
    "# (optional) small AnnData wrapper for Scanpy/UMAP downstream\n",
    "import scanpy as sc, anndata as ad\n",
    "adata_latent = ad.AnnData(\n",
    "        X            = latent_t.cpu().numpy(),\n",
    "        obs          = pd.DataFrame(index=[f\"cell_{i}\" for i in range(N)]),\n",
    "        var          = pd.DataFrame(index=[f\"z{i}\"     for i in range(EMBED_DIM)]),\n",
    "    )\n",
    "adata_latent.obsm[\"spatial\"] = C_np          # keep coords\n",
    "adata_latent.write(PP_DIR / \"latent.h5ad\")\n",
    "print(\"AnnData written →\", PP_DIR / \"latent.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35a04c-7940-4a62-a0f1-4e96f59db36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6  ──────────────────────────────────────────────────────────────\n",
    "import scanpy as sc\n",
    "\n",
    "sc.pp.neighbors(adata_latent, n_neighbors=15, use_rep=\"X\")\n",
    "sc.tl.umap(adata_latent)\n",
    "sc.tl.leiden(adata_latent, resolution=0.6)\n",
    "\n",
    "sc.pl.umap(\n",
    "    adata_latent,\n",
    "    color=[\"leiden\"],\n",
    "    size=20\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spaformer)",
   "language": "python",
   "name": "spaformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
